<!DOCTYPE HTML>
<html class="no-js" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <!--[if lte IE 9]>
<meta http-equiv="refresh" content="0;url=http://southrivers.github.io/warn.html">
<![endif]-->
<meta charset="utf-8">
<meta http-equiv="X-DNS-Prefetch-Control" content="on">
<link rel="dns-prefetch" href="http://southrivers.github.io">
<link rel="dns-prefetch" href="//www.google-analytics.com">
<link rel="prefetch" href="http://southrivers.github.io">
<link rel="prefetch" href="//www.google-analytics.com">


<link rel="prerender" href="http://southrivers.github.io">

<meta http-equiv="X-UA-Compatible" content="IE=Edge">
<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width, initial-scale=1.0,user-scalable=no">
<meta http-equiv="mobile-agent" content="format=html5; url=http://southrivers.github.io">
<meta name="author" content="John Doe">
<link rel="stylesheet" href="/css/JSimple.css">

<link rel="shortcut icon" href="/images/favicon.png">


<title>flink 解析 - 离亭燕</title>

<meta name="keywords" content>

<meta name="description " content>

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
            }
        });
    </script>


    

    

</head>
<body>
<div id="nav">
    <nav class="nav-menu">
        <a class="site-name current" href="/" title="夏">夏</a>
        <a class="site-index current" href="/"><i class="fa fa-home"></i><span>首页</span></a>
        <a href="/archives" title="归档"><i class="fa fa-archives"></i><span>归档</span></a>

        <!-- custom single page of menus -->
        
    </nav>
</div>

<div class="nav-user">
    <a class="btn-search" href="#"><i class="fa fa-search"></i></a>
    <a class="btn-read-mode" href="#"><i class="fa fa-sun-o"></i></a>
    <a class="btn-sns-qr" href="javascript:"><i class="fa fa-telegram"></i></a>
</div>

<div id="wrapper" class="clearfix">
    <div id="body">
        <div class="main" id="main">
            <div id="cover">
    <div class="cover-img"></div>
    <div class="cover-info">
        
        <h1 class="cover-siteName">血刀老祖</h1>
        <h3 class="cover-siteTitle">码个蛋</h3>
        <p class="cover-siteDesc">东门黄犬</p>
        <div class="cover-sns">
            

        </div>
    </div>
</div>

            <div class="page-title">
    <ul>
        <li><a href="/">最近</a></li>
        

        
        <li class="page-search">
    <form id="search" class="search-form">
        <input type="text" readonly="readonly" id="local-search-input-tip" placeholder="读物检索~">
        <button type="button" disabled="disabled" class="search-form-submit"><i class="fa fa-search"></i></button>
    </form>
</li>

    </ul>
</div>
<div class="main-inner">
    <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="post-header">
            <div class="post-author clearfix">
                <a class="avatar fleft" href="http://southrivers.github.io" target="_blank">
                    <img width="48" src="/images/favicon.png" alt="avatar">
                </a>
                <p><span class="label">author</span>
                    <a href="http://southrivers.github.io" target="_blank">原站</a>
                    <span title="last_edited&nbsp;2022-08-20">2022-08-20</span>
                </p>
                <p>码个蛋️️</p>
            </div>
            <h2 class="post-title">flink 解析</h2>

        </div>
        <div class="post-content markdown-body">
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>流式计算框架常见的有storm、spark streaming、flink，其中storm和spark streaming出现的时间比较久了，storm应用在对实时性要求比较高的场景，不过其吞吐却比较低，有幸在15年左右的时候使用过storm做开发，其在数据一致性上也比较堪忧，新生的spark streaming可以看作是storm的替代品，不过其采用的却不是流式模型，而是采用的微批次，相较于storm来说其吞吐有了很大的提升，不过我们在做监控业务的时候依然遇到很多问题，其中一个比较重要的问题就是对延迟数据的处理，通常这种流式处理框架都会对接kafka，不过发送到kafka的数据由于分区、延迟等情况可能会导致数据乱序、迟到，在做聚合操作的时候就会产生数据丢失的情况，对于上述情景，有人提出lambda的架构，也就是将实时和批处理同时进行，不过现在又了更好的解决方案flink，flink相较于spark streaming来说其属于实时的处理模型，并不再是微批次，另外其可以针对迟到的数据进行相应的处理，同时能够保障exactly-once的语义，当前工作的环境在大力的推广flink，原本由spark streaming处理的工作现在更多的交给了flink。因此抽时间好好整理一下flink及其相关特性。</p>
<h1 id="详解"><a href="#详解" class="headerlink" title="详解"></a>详解</h1><h2 id="作业提交流程分析"><a href="#作业提交流程分析" class="headerlink" title="作业提交流程分析"></a>作业提交流程分析</h2><p>在深入了解flink特性之前，我们先通过简单的实例来分析一下flink中作业的提交的流程，首先我们引入如下依赖，pom依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">flink.version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">flink.version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">scala.binary.version</span>&gt;</span>2.11<span class="tag">&lt;/<span class="name">scala.binary.version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">id</span>&gt;</span>apache.snapshots<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>Apache Development Snapshot Repository<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.apache.org/content/repositories/snapshots/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">releases</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">releases</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- Apache Flink dependencies --&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- These dependencies are provided, because they should not be packaged into the JAR file. --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--			&lt;scope&gt;provided&lt;/scope&gt;--&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--			&lt;scope&gt;provided&lt;/scope&gt;--&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.17<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>示例代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.myorg.quickstart;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.JobExecutionResult;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.ReduceFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.core.execution.JobClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.core.execution.JobListener;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.Nullable;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Skeleton for a Flink Streaming Job.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;For a tutorial how to write a Flink streaming application, check the</span></span><br><span class="line"><span class="comment"> * tutorials and examples on the &lt;a href="https://flink.apache.org/docs/stable/"&gt;Flink Website&lt;/a&gt;.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;To package your application into a JAR file for execution, run</span></span><br><span class="line"><span class="comment"> * 'mvn clean package' on the command line.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;If you change the name of the main class (with the public static void main(String[] args))</span></span><br><span class="line"><span class="comment"> * method, change the respective entry in the POM.xml file (simply search for 'mainClass').</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StreamingJob</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="comment">// set up the streaming execution environment</span></span><br><span class="line">		<span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">		env.registerJobListener(<span class="keyword">new</span> JobListener() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onJobSubmitted</span><span class="params">(@Nullable JobClient jobClient, @Nullable Throwable throwable)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onJobExecuted</span><span class="params">(@Nullable JobExecutionResult jobExecutionResult, @Nullable Throwable throwable)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line"></span><br><span class="line">		DataStream&lt;String&gt; ds= env.socketTextStream(<span class="string">"localhost"</span>, <span class="number">8888</span>);</span><br><span class="line">		DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; text = ds.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">				<span class="keyword">for</span> (String word : s.split(<span class="string">"\\s"</span>)) &#123;</span><br><span class="line">					collector.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(word, <span class="number">1</span>));</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;).keyBy(<span class="number">0</span>).timeWindow(Time.seconds(<span class="number">5</span>), Time.seconds(<span class="number">5</span>)).reduce(<span class="keyword">new</span> ReduceFunction&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">reduce</span><span class="params">(Tuple2&lt;String, Integer&gt; stringIntegerTuple2, Tuple2&lt;String, Integer&gt; t1)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">				<span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(t1.f0, t1.f1+ stringIntegerTuple2.f1);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line"></span><br><span class="line">		text.print().setParallelism(<span class="number">1</span>);</span><br><span class="line">		<span class="comment">// execute program</span></span><br><span class="line">		env.execute(<span class="string">"Flink Streaming Java API Skeleton"</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>针对上述代码，我们来简单的分析一下作业的执行流程：</p>
<ul>
<li><p>创建执行环境<code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</code>，这一步可以看作是创建一个容器，也即是该env，后续作业的相关信息、配置相关的信息都会存放在该env中。</p>
</li>
<li><p>接下来向该env添加source、transform、sink，值得注意的是这里的<code>text.print()</code>其实就是添加了一个sink，其具体代码如下：</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DataStreamSink&lt;T&gt; <span class="title">print</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    PrintSinkFunction&lt;T&gt; printFunction = <span class="keyword">new</span> PrintSinkFunction&lt;&gt;();</span><br><span class="line">    <span class="keyword">return</span> addSink(printFunction).name(<span class="string">"Print to Std. Out"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>触发作业的执行，这一步信息量有点大，不过大概的流程如下：
<img src="//southrivers.github.io/2022/08/20/flink-解析/jobsubmit.png" alt>
我们接下来分析一下这些对象创建的时机及作业提交、运行的时机</p>
<ul>
<li><p>根据前面的source、transform、sink信息，生成streamgraph，具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">	<span class="function"><span class="keyword">public</span> StreamGraph <span class="title">getStreamGraph</span><span class="params">(String jobName, <span class="keyword">boolean</span> clearTransformations)</span> </span>&#123;</span><br><span class="line">	StreamGraph streamGraph = getStreamGraphGenerator().setJobName(jobName).generate();</span><br><span class="line">	<span class="keyword">if</span> (clearTransformations) &#123;</span><br><span class="line">		<span class="keyword">this</span>.transformations.clear();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> streamGraph;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>env根据给定的streamgraph初始化一些必须的对象，并执行作业，这里会调用env的<code>execute(streamgraph)</code>方法，不过这个时候作业运行的所有必须的对象都还没有初始化，该过程接下来就会创建这些必须的对象并真正的执行作业。核心代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> JobClient jobClient = executeAsync(streamGraph);</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>上面代码看起来是创建jobclient，不过该过程是最复杂的过程。接下来跟进一下代码来看一该步骤对应的操作有哪些：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> JobClient <span class="title">executeAsync</span><span class="params">(StreamGraph streamGraph)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	...</span><br><span class="line">	CompletableFuture&lt;JobClient&gt; jobClientFuture = executorFactory</span><br><span class="line">		.getExecutor(configuration)</span><br><span class="line">		.execute(streamGraph, configuration);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		JobClient jobClient = jobClientFuture.get();</span><br><span class="line">		jobListeners.forEach(jobListener -&gt; jobListener.onJobSubmitted(jobClient, <span class="keyword">null</span>));</span><br><span class="line">		<span class="keyword">return</span> jobClient;</span><br><span class="line">	&#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">		...</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码的核心是<code>jobClientFuture</code>的创建，这一步创建一个<code>executor</code>对象，该对象封装了一些执行作业的方法，因此可以看到接下来就会调用<code>execute</code>方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;JobClient&gt; <span class="title">execute</span><span class="params">(Pipeline pipeline, Configuration configuration)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	checkNotNull(pipeline);</span><br><span class="line">	checkNotNull(configuration);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// we only support attached execution with the local executor.</span></span><br><span class="line">	checkState(configuration.getBoolean(DeploymentOptions.ATTACHED));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">final</span> JobGraph jobGraph = getJobGraph(pipeline, configuration);</span><br><span class="line">	<span class="keyword">final</span> MiniCluster miniCluster = startMiniCluster(jobGraph, configuration);</span><br><span class="line">	<span class="keyword">final</span> MiniClusterClient clusterClient = <span class="keyword">new</span> MiniClusterClient(configuration, miniCluster);</span><br><span class="line"></span><br><span class="line">	CompletableFuture&lt;JobID&gt; jobIdFuture = clusterClient.submitJob(jobGraph);</span><br><span class="line"></span><br><span class="line">	jobIdFuture</span><br><span class="line">			.thenCompose(clusterClient::requestJobResult)</span><br><span class="line">			.thenAccept((jobResult) -&gt; clusterClient.shutDownCluster());</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> jobIdFuture.thenApply(jobID -&gt;</span><br><span class="line">			<span class="keyword">new</span> ClusterClientJobClientAdapter&lt;&gt;(() -&gt; clusterClient, jobID));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>首先会生成jobgraph，这一步是基于stream而生成的，还可以看到<strong>jobgraph的生成是在cluster、client的创建之前完成的</strong>，加下来创建cluster、clusterclient并借助client提交作业到集群，可以看到该client提交的作业为jobgraph，并不是streamgraph。接下来还涉及到的资源就是jobmanager、taskmanager了，其中taskmanager的创建是在<code>startMiniCluster</code>的过程中创建的，：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> 	<span class="function"><span class="keyword">private</span> MiniCluster <span class="title">startMiniCluster</span><span class="params">(<span class="keyword">final</span> JobGraph jobGraph, <span class="keyword">final</span> Configuration configuration)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (!configuration.contains(RestOptions.BIND_PORT)) &#123;</span><br><span class="line">		configuration.setString(RestOptions.BIND_PORT, <span class="string">"0"</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">int</span> numTaskManagers = configuration.getInteger(</span><br><span class="line">			ConfigConstants.LOCAL_NUMBER_TASK_MANAGER,</span><br><span class="line">			ConfigConstants.DEFAULT_LOCAL_NUMBER_TASK_MANAGER);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// we have to use the maximum parallelism as a default here, otherwise streaming</span></span><br><span class="line">	<span class="comment">// pipelines would not run</span></span><br><span class="line">	<span class="keyword">int</span> numSlotsPerTaskManager = configuration.getInteger(</span><br><span class="line">			TaskManagerOptions.NUM_TASK_SLOTS,</span><br><span class="line">			jobGraph.getMaximumParallelism());</span><br><span class="line"></span><br><span class="line">	<span class="keyword">final</span> MiniClusterConfiguration miniClusterConfiguration =</span><br><span class="line">			<span class="keyword">new</span> MiniClusterConfiguration.Builder()</span><br><span class="line">					.setConfiguration(configuration)</span><br><span class="line">					.setNumTaskManagers(numTaskManagers)</span><br><span class="line">					.setRpcServiceSharing(RpcServiceSharing.SHARED)</span><br><span class="line">					.setNumSlotsPerTaskManager(numSlotsPerTaskManager)</span><br><span class="line">					.build();</span><br><span class="line"></span><br><span class="line">	<span class="keyword">final</span> MiniCluster miniCluster = <span class="keyword">new</span> MiniCluster(miniClusterConfiguration);</span><br><span class="line">	miniCluster.start();</span><br><span class="line"></span><br><span class="line">	configuration.setInteger(RestOptions.PORT, miniCluster.getRestAddress().get().getPort());</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> miniCluster;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来可以看到启动集群的过程中就会创建taskmanager</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"> 	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	<span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">		checkState(!running, <span class="string">"MiniCluster is already running"</span>);</span><br><span class="line"></span><br><span class="line">		LOG.info(<span class="string">"Starting Flink Mini Cluster"</span>);</span><br><span class="line">		LOG.debug(<span class="string">"Using configuration &#123;&#125;"</span>, miniClusterConfiguration);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">final</span> Configuration configuration = miniClusterConfiguration.getConfiguration();</span><br><span class="line">		<span class="keyword">final</span> <span class="keyword">boolean</span> useSingleRpcService = miniClusterConfiguration.getRpcServiceSharing() == RpcServiceSharing.SHARED;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			initializeIOFormatClasses(configuration);</span><br><span class="line"></span><br><span class="line">			LOG.info(<span class="string">"Starting Metrics Registry"</span>);</span><br><span class="line">			metricRegistry = createMetricRegistry(configuration);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// bring up all the RPC services</span></span><br><span class="line">			LOG.info(<span class="string">"Starting RPC Service(s)"</span>);</span><br><span class="line"></span><br><span class="line">			AkkaRpcServiceConfiguration akkaRpcServiceConfig = AkkaRpcServiceConfiguration.fromConfiguration(configuration);</span><br><span class="line"></span><br><span class="line">			<span class="keyword">final</span> RpcServiceFactory dispatcherResourceManagreComponentRpcServiceFactory;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> (useSingleRpcService) &#123;</span><br><span class="line">				<span class="comment">// we always need the 'commonRpcService' for auxiliary calls</span></span><br><span class="line">				commonRpcService = createRpcService(akkaRpcServiceConfig, <span class="keyword">false</span>, <span class="keyword">null</span>);</span><br><span class="line">				<span class="keyword">final</span> CommonRpcServiceFactory commonRpcServiceFactory = <span class="keyword">new</span> CommonRpcServiceFactory(commonRpcService);</span><br><span class="line">				taskManagerRpcServiceFactory = commonRpcServiceFactory;</span><br><span class="line">				dispatcherResourceManagreComponentRpcServiceFactory = commonRpcServiceFactory;</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				<span class="comment">// we always need the 'commonRpcService' for auxiliary calls</span></span><br><span class="line">				commonRpcService = createRpcService(akkaRpcServiceConfig, <span class="keyword">true</span>, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">				<span class="comment">// start a new service per component, possibly with custom bind addresses</span></span><br><span class="line">				<span class="keyword">final</span> String jobManagerBindAddress = miniClusterConfiguration.getJobManagerBindAddress();</span><br><span class="line">				<span class="keyword">final</span> String taskManagerBindAddress = miniClusterConfiguration.getTaskManagerBindAddress();</span><br><span class="line"></span><br><span class="line">				dispatcherResourceManagreComponentRpcServiceFactory = <span class="keyword">new</span> DedicatedRpcServiceFactory(akkaRpcServiceConfig, jobManagerBindAddress);</span><br><span class="line">				taskManagerRpcServiceFactory = <span class="keyword">new</span> DedicatedRpcServiceFactory(akkaRpcServiceConfig, taskManagerBindAddress);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			RpcService metricQueryServiceRpcService = MetricUtils.startMetricsRpcService(</span><br><span class="line">				configuration,</span><br><span class="line">				commonRpcService.getAddress());</span><br><span class="line">			metricRegistry.startQueryService(metricQueryServiceRpcService, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">			processMetricGroup = MetricUtils.instantiateProcessMetricGroup(</span><br><span class="line">				metricRegistry,</span><br><span class="line">				RpcUtils.getHostname(commonRpcService),</span><br><span class="line">				ConfigurationUtils.getSystemResourceMetricsProbingInterval(configuration));</span><br><span class="line"></span><br><span class="line">			ioExecutor = Executors.newFixedThreadPool(</span><br><span class="line">				Hardware.getNumberCPUCores(),</span><br><span class="line">				<span class="keyword">new</span> ExecutorThreadFactory(<span class="string">"mini-cluster-io"</span>));</span><br><span class="line">			haServices = createHighAvailabilityServices(configuration, ioExecutor);</span><br><span class="line"></span><br><span class="line">			blobServer = <span class="keyword">new</span> BlobServer(configuration, haServices.createBlobStore());</span><br><span class="line">			blobServer.start();</span><br><span class="line"></span><br><span class="line">			heartbeatServices = HeartbeatServices.fromConfiguration(configuration);</span><br><span class="line"></span><br><span class="line">			blobCacheService = <span class="keyword">new</span> BlobCacheService(</span><br><span class="line">				configuration, haServices.createBlobStore(), <span class="keyword">new</span> InetSocketAddress(InetAddress.getLocalHost(), blobServer.getPort())</span><br><span class="line">			);</span><br><span class="line">			<span class="comment">// 这一步创建并启动taskmanager</span></span><br><span class="line">			startTaskManagers();</span><br><span class="line"></span><br><span class="line">			MetricQueryServiceRetriever metricQueryServiceRetriever = <span class="keyword">new</span> RpcMetricQueryServiceRetriever(metricRegistry.getMetricQueryServiceRpcService());</span><br><span class="line"></span><br><span class="line">			setupDispatcherResourceManagerComponents(configuration, dispatcherResourceManagreComponentRpcServiceFactory, metricQueryServiceRetriever);</span><br><span class="line"></span><br><span class="line">			resourceManagerLeaderRetriever = haServices.getResourceManagerLeaderRetriever();</span><br><span class="line">			dispatcherLeaderRetriever = haServices.getDispatcherLeaderRetriever();</span><br><span class="line">			clusterRestEndpointLeaderRetrievalService = haServices.getClusterRestEndpointLeaderRetriever();</span><br><span class="line"></span><br><span class="line">			dispatcherGatewayRetriever = <span class="keyword">new</span> RpcGatewayRetriever&lt;&gt;(</span><br><span class="line">				commonRpcService,</span><br><span class="line">				DispatcherGateway<span class="class">.<span class="keyword">class</span>,</span></span><br><span class="line">				DispatcherId::fromUuid,</span><br><span class="line">				<span class="number">20</span>,</span><br><span class="line">				Time.milliseconds(<span class="number">20L</span>));</span><br><span class="line">			resourceManagerGatewayRetriever = <span class="keyword">new</span> RpcGatewayRetriever&lt;&gt;(</span><br><span class="line">				commonRpcService,</span><br><span class="line">				ResourceManagerGateway<span class="class">.<span class="keyword">class</span>,</span></span><br><span class="line">				ResourceManagerId::fromUuid,</span><br><span class="line">				<span class="number">20</span>,</span><br><span class="line">				Time.milliseconds(<span class="number">20L</span>));</span><br><span class="line">			webMonitorLeaderRetriever = <span class="keyword">new</span> LeaderRetriever();</span><br><span class="line"></span><br><span class="line">			resourceManagerLeaderRetriever.start(resourceManagerGatewayRetriever);</span><br><span class="line">			dispatcherLeaderRetriever.start(dispatcherGatewayRetriever);</span><br><span class="line">			clusterRestEndpointLeaderRetrievalService.start(webMonitorLeaderRetriever);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">			<span class="comment">// cleanup everything</span></span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				close();</span><br><span class="line">			&#125; <span class="keyword">catch</span> (Exception ee) &#123;</span><br><span class="line">				e.addSuppressed(ee);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">throw</span> e;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// create a new termination future</span></span><br><span class="line">		terminationFuture = <span class="keyword">new</span> CompletableFuture&lt;&gt;();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// now officially mark this as running</span></span><br><span class="line">		running = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">		LOG.info(<span class="string">"Flink Mini Cluster started successfully"</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在完成taskmanager的创建并启动之后，接下来会进行作业的提交<code>submitJob</code>，该过程会创建对应的jobmanager，如下minicluster中提交作业的方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> 	<span class="function"><span class="keyword">public</span> CompletableFuture&lt;JobSubmissionResult&gt; <span class="title">submitJob</span><span class="params">(JobGraph jobGraph)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;DispatcherGateway&gt; dispatcherGatewayFuture = getDispatcherGatewayFuture();</span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;InetSocketAddress&gt; blobServerAddressFuture = createBlobServerAddress(dispatcherGatewayFuture);</span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;Void&gt; jarUploadFuture = uploadAndSetJobFiles(blobServerAddressFuture, jobGraph);</span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;Acknowledge&gt; acknowledgeCompletableFuture = jarUploadFuture</span><br><span class="line">		.thenCombine(</span><br><span class="line">			<span class="comment">// 提交作业</span></span><br><span class="line">			dispatcherGatewayFuture,</span><br><span class="line">			(Void ack, DispatcherGateway dispatcherGateway) -&gt; dispatcherGateway.submitJob(jobGraph, rpcTimeout))</span><br><span class="line">		.thenCompose(Function.identity());</span><br><span class="line">	<span class="keyword">return</span> acknowledgeCompletableFuture.thenApply(</span><br><span class="line">		(Acknowledge ignored) -&gt; <span class="keyword">new</span> JobSubmissionResult(jobGraph.getJobID()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述在minicluster中提交的作业会经由dispatcher#submitJob进行提交,最终进入该方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"> 	<span class="function"><span class="keyword">private</span> CompletableFuture&lt;Acknowledge&gt; <span class="title">internalSubmitJob</span><span class="params">(JobGraph jobGraph)</span> </span>&#123;</span><br><span class="line">	log.info(<span class="string">"Submitting job &#123;&#125; (&#123;&#125;)."</span>, jobGraph.getJobID(), jobGraph.getName());</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 持久化作业并运行</span></span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;Acknowledge&gt; persistAndRunFuture = waitForTerminatingJobManager(jobGraph.getJobID(), jobGraph, <span class="keyword">this</span>::persistAndRunJob)</span><br><span class="line">		.thenApply(ignored -&gt; Acknowledge.get());</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> persistAndRunFuture.handleAsync((acknowledge, throwable) -&gt; &#123;</span><br><span class="line">		<span class="keyword">if</span> (throwable != <span class="keyword">null</span>) &#123;</span><br><span class="line">			cleanUpJobData(jobGraph.getJobID(), <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">			<span class="keyword">final</span> Throwable strippedThrowable = ExceptionUtils.stripCompletionException(throwable);</span><br><span class="line">			log.error(<span class="string">"Failed to submit job &#123;&#125;."</span>, jobGraph.getJobID(), strippedThrowable);</span><br><span class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> CompletionException(</span><br><span class="line">				<span class="keyword">new</span> JobSubmissionException(jobGraph.getJobID(), <span class="string">"Failed to submit job."</span>, strippedThrowable));</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> acknowledge;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;, getRpcService().getExecutor());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述过程中通过<code>persistAndRunJob</code>会将作业持久化并运行，持久化的方式可以是写到zk的节点中，需要看具体实现，上述方法最终会进入dispatcher#runJob的方法里面，接下来会进入dispatcher#createJobManagerRunner的方法里面，上述方法最终会进入：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> 	<span class="function"><span class="keyword">private</span> CompletableFuture&lt;JobManagerRunner&gt; <span class="title">createJobManagerRunner</span><span class="params">(JobGraph jobGraph)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">final</span> RpcService rpcService = getRpcService();</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> CompletableFuture.supplyAsync(</span><br><span class="line">		CheckedSupplier.unchecked(() -&gt;</span><br><span class="line">			jobManagerRunnerFactory.createJobManagerRunner(</span><br><span class="line">				jobGraph,</span><br><span class="line">				configuration,</span><br><span class="line">				rpcService,</span><br><span class="line">				highAvailabilityServices,</span><br><span class="line">				heartbeatServices,</span><br><span class="line">				jobManagerSharedServices,</span><br><span class="line">				<span class="keyword">new</span> DefaultJobManagerJobMetricGroupFactory(jobManagerMetricGroup),</span><br><span class="line">				fatalErrorHandler)),</span><br><span class="line">		rpcService.getExecutor());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>也即会调用<code>jobManagerRunnerFactory#createJobManagerRunner</code>的方法，上面会创建<code>JobManagerRunnerImpl</code>对象，该对象的创建最终会进入如下方法调用：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.jobMasterService = jobMasterFactory.createJobMasterService(jobGraph, <span class="keyword">this</span>, userCodeLoader);</span><br></pre></td></tr></table></figure>

<p>最终会完成jobmaster的创建，这里的jobmaster就是jobmanager（该类的命名不知道为啥不是jobmanager而是jobmaster），接下来在jobmanger创建完成后，在<code>dispatcher#runjob</code>中会通过<code>startJobManagerRunner</code>启动jobmanager执行作业 <code>startJobManagerRunner</code>，至此作业的提交就完成了。不过不确定这种作业提交流程在yarn session或者per-job的模式下就会有所不同了，这种不同体现在dispatcher提交过去的作业并不会直接创建jobmaster或者taskmanager，而是会首先创建jobmaster，经由jobmaster向resourcemanager申请所需要的资源，之后resourcemanager会创建taskmanager并同jobmaster取得心跳联系，接下来作业就可以正常的提交并执行了。yarn session和per-job的模式区别点在于yarn session对于提交过来的作业资源不做隔离，而且有执行失败的风险，per-job则解除了这种限制，不同的作业其资源并不贡献，因此作业之间不存在资源竞争。</p>
</li>
</ul>
<p>可以看到上述作业提交的过程中几个重要角色：client、dispatcher、jobmanager、taskmanager。</p>
<h2 id="部署模式"><a href="#部署模式" class="headerlink" title="部署模式"></a>部署模式</h2><p>flink的部署模式存在local、standlone、yarn这几种模式，其中flink on yarn的模式又可以per-job和yarn session模式，我们来分析一下这几种模式的区别：</p>
<ul>
<li>local： 我们直接解压flink的压缩包，并通过start-cluster脚本就可以直接启动这种模式，不过这种模式的flink集群在提交作业之后jobmanager和taskmanager在同一个节点上，<strong>不确定这种模式是否会有jobmanager直接启动，如果没有，我们的作业提交是提交到什么进程呢？</strong></li>
<li>standlone：对于这种模式，是采用比较经典的主从模式，即存在master、slave节点，通常是一主多从的模式，这种模式也有很大的局限性，无法做到高可用，在生产环境中多半也不会使用</li>
<li>yarn：这种模式依赖于hadoop集群，并且通常我们还需要用到zookeeper集群，hadoop集群提供yarn的环境，zookeeper则用于保障flink集群的HA，基于yarn的模式也分了两种情况<ul>
<li>flink on yarn：这种方式在client提交了作业之后会生成对应的jobmanager，jobmanager会从yarn的resourcemanager申请对应的资源，该过程会创建taskmanager，这种情况下不同的作业彼此之间的资源是隔离的</li>
<li>yarn session：这种方式要求先创建一个yarn的session，在创建session的时候我们会指定该session的资源，接下来我们在提交作业的时候会指定作业使用的yarn session，如果我们提交的作业该session无法满足，那么该作业的运行将会进入阻塞的状态，直到有足够的资源释放出来，该模式存在的问题就是作业之间的资源是不隔离的，如果yarn session因为某种原因异常退出，那么该session托管的所有作业都将会被kill掉。</li>
</ul>
</li>
</ul>
<p>上述过程中依然存在理解障碍的地方在于集群运行的常驻进程究竟是什么？？？？？？</p>
<h2 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h2><p>通过上面作业提交流程的分析，我们对flink有了一个感性的认识后，我们接下来介绍一下flink的编程模型：
<img src="//southrivers.github.io/2022/08/20/flink-解析/programmodal.png" alt>
我们一般使用的是DataSet、DataStream级别的接口进行数据的处理，对于简单的应用场景来说我们也可以使用table或者sql API来进行编程，这种编程模式是采用了apache calcite来进行sql的解析，不过对于程序的优化就显得无能为力了。</p>
<p>算子是一个一个的运算，可以将其看作一个类，任务是算子在运行时候的体现，因此当我们设定了算子的并行度的时候，其会在任务执行的时候体现，比如我们设定某个算子的并行度为8，那么该算子对应的任务在执行的时候就会有8个，这些被切分的task叫做subtask，subtask是针对一个算子的切分，而不是operater进行chain之后的切分。</p>
<h3 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h3><p>keyedStream、nonkeyedStream</p>
<h3 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h3><h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h3><p>在日常的开发过程中我们难免会遇到需要使用缓存的情况，flink给我们提供了分布式缓存的能力，这些分布式缓存可以从本地文件中读取，也可以从hdfs中读取，并且最终会缓存到taskmanager的对内存中，因此这份缓存不应该太大，因为可能会导致jvm 的 OOM，我们可以通过一个示例来演示一下分布式缓存的使用，我们还是使用上面的示例来说明：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.myorg.quickstart;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.JobExecutionResult;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.ReduceFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.RichMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.core.execution.JobClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.core.execution.JobListener;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.FileUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.Nullable;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Skeleton for a Flink Streaming Job.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;For a tutorial how to write a Flink streaming application, check the</span></span><br><span class="line"><span class="comment"> * tutorials and examples on the &lt;a href="https://flink.apache.org/docs/stable/"&gt;Flink Website&lt;/a&gt;.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;To package your application into a JAR file for execution, run</span></span><br><span class="line"><span class="comment"> * 'mvn clean package' on the command line.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;If you change the name of the main class (with the public static void main(String[] args))</span></span><br><span class="line"><span class="comment"> * method, change the respective entry in the POM.xml file (simply search for 'mainClass').</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StreamingJob</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="comment">// set up the streaming execution environment</span></span><br><span class="line">		<span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">		env.registerJobListener(<span class="keyword">new</span> JobListener() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onJobSubmitted</span><span class="params">(@Nullable JobClient jobClient, @Nullable Throwable throwable)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onJobExecuted</span><span class="params">(@Nullable JobExecutionResult jobExecutionResult, @Nullable Throwable throwable)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line"></span><br><span class="line">		env.registerCachedFile(<span class="string">"/Users/shuaizi/workspace/github/flink/quickstart/hello.txt"</span>, <span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">		DataStream&lt;String&gt; ds= env.socketTextStream(<span class="string">"localhost"</span>, <span class="number">8888</span>);</span><br><span class="line">		DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; text = ds.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line"></span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">				<span class="keyword">for</span> (String word : s.split(<span class="string">"\\s"</span>)) &#123;</span><br><span class="line">					collector.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(word, <span class="number">1</span>));</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;).map(<span class="keyword">new</span> MyMapper()).keyBy(<span class="number">0</span>).timeWindow(Time.seconds(<span class="number">5</span>), Time.seconds(<span class="number">5</span>)).reduce(<span class="keyword">new</span> ReduceFunction&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">reduce</span><span class="params">(Tuple2&lt;String, Integer&gt; stringIntegerTuple2, Tuple2&lt;String, Integer&gt; t1)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">				<span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(t1.f0, t1.f1+ stringIntegerTuple2.f1);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line"></span><br><span class="line">		text.print().setParallelism(<span class="number">1</span>);</span><br><span class="line">		<span class="comment">// execute program</span></span><br><span class="line">		env.execute(<span class="string">"Flink Streaming Java API Skeleton"</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment">// TODO 待确认这些对象是每批次都创建，还是说开始创建好了后面重复利用，如果重复利用的话说明是有状态的，这也合理的解释了微批次和流失的最大区别，流失的节点是算子</span></span><br><span class="line">	<span class="comment">// TODO 批处理节点是数据，或许可以按照上述的思路进行理解</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">RichMapFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">		<span class="keyword">private</span> String fileContent = <span class="keyword">null</span>;</span><br><span class="line">		<span class="comment">//TODO 确定调用的先后顺序，及调用次数，是否是初始化一次之后后续就不再调用？</span></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">			File file = getRuntimeContext().getDistributedCache().getFile(<span class="string">"test"</span>);</span><br><span class="line">			System.out.println(<span class="string">"--------- run times test ------------"</span>);</span><br><span class="line">			fileContent = FileUtils.readFileUtf8(file);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">map</span><span class="params">(Tuple2&lt;String, Integer&gt; value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">			value.f0 = value.f0 + <span class="string">"@@"</span> + fileContent;</span><br><span class="line">			<span class="keyword">return</span> value;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面关于分布式缓存的使用大概经历了以下两个步骤：</p>
<ul>
<li>注册缓存，有两种方式分别是本地文件或者hdfs上的文件</li>
<li>获取运行时环境，并通过注册时候指定的缓存的名称获取对应的缓存信息</li>
</ul>
<p>运行程序并输入测试数据：
<img src="//southrivers.github.io/2022/08/20/flink-解析/ncter.png" alt>
上面程序运行结果最终如下：
<img src="//southrivers.github.io/2022/08/20/flink-解析/cacheexe.png" alt>
上图可以看到MyMapper这个函数的open方法被执行了8次，这是因为我的并行度设置的是8，启动了8个slot（只有一个taskmanager），每个taskmanager的slot在启动的时候都会读取该缓存数据，不过在程序执行的时候就不会在此执行open方法了，可以看到只有在Mapper对象初始化的时候才会执行一次。下面我们来通过源码看一下分布式缓存在初始化的时候的使用：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">env.registerCachedFile(<span class="string">"/Users/shuaizi/workspace/github/flink/quickstart/hello.txt"</span>, <span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">org.apache.flink.streaming.api.environment.StreamExecutionEnvironment#registerCachedFile(java.lang.String, java.lang.String, boolean)&#123;</span><br><span class="line">		<span class="keyword">this</span>.cacheFile.add(<span class="keyword">new</span> Tuple2&lt;&gt;(name, <span class="keyword">new</span> DistributedCache.DistributedCacheEntry(filePath, executable)));</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到注册的过程本质是将需要保存的对象的相关信息保存到一个list中，接下来会在生成streamgraph的时候将这些cache传入streamgraph对象中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">org.apache.flink.streaming.api.environment.StreamExecutionEnvironment#getStreamGraphGenerator() &#123;</span><br><span class="line">		<span class="keyword">if</span> (transformations.size() &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"No operators defined in streaming topology. Cannot execute."</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> StreamGraphGenerator(transformations, config, checkpointCfg)</span><br><span class="line">			.setStateBackend(defaultStateBackend)</span><br><span class="line">			.setChaining(isChainingEnabled)</span><br><span class="line">			.setUserArtifacts(cacheFile)</span><br><span class="line">			.setTimeCharacteristic(timeCharacteristic)</span><br><span class="line">			.setDefaultBufferTimeout(bufferTimeout);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到该缓存对象最终保存到 <code>userArtifacts</code> 这个字段中了，在创建完streamgraph之后会调用execute方法来执行，不过前面我们已经知道，在执行作业之前还需要将streamgraph转换成jobgraph，在生成jobgraph的过程中会调用对应的方法将缓存文件取出并设置到jobgraph相关的字段中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">org.apache.flink.optimizer.plantranslate.JobGraphGenerator#addUserArtifactEntries(Collection&lt;Tuple2&lt;String, DistributedCache.DistributedCacheEntry&gt;&gt; userArtifacts, JobGraph jobGraph) &#123;</span><br><span class="line">		<span class="keyword">if</span> (userArtifacts != <span class="keyword">null</span> &amp;&amp; !userArtifacts.isEmpty()) &#123;</span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				java.nio.file.Path tmpDir = Files.createTempDirectory(<span class="string">"flink-distributed-cache-"</span> + jobGraph.getJobID());</span><br><span class="line">				<span class="keyword">for</span> (Tuple2&lt;String, DistributedCache.DistributedCacheEntry&gt; originalEntry : userArtifacts) &#123;</span><br><span class="line">					Path filePath = <span class="keyword">new</span> Path(originalEntry.f1.filePath);</span><br><span class="line">					<span class="keyword">boolean</span> isLocalDir = <span class="keyword">false</span>;</span><br><span class="line">					<span class="keyword">try</span> &#123;</span><br><span class="line">						FileSystem sourceFs = filePath.getFileSystem();</span><br><span class="line">						isLocalDir = !sourceFs.isDistributedFS() &amp;&amp; sourceFs.getFileStatus(filePath).isDir();</span><br><span class="line">					&#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">						LOG.warn(<span class="string">"Could not determine whether &#123;&#125; denotes a local path."</span>, filePath, ioe);</span><br><span class="line">					&#125;</span><br><span class="line">					<span class="comment">// zip local directories because we only support file uploads</span></span><br><span class="line">					DistributedCache.DistributedCacheEntry entry;</span><br><span class="line">					<span class="keyword">if</span> (isLocalDir) &#123;</span><br><span class="line">						Path zip = FileUtils.compressDirectory(filePath, <span class="keyword">new</span> Path(tmpDir.toString(), filePath.getName() + <span class="string">".zip"</span>));</span><br><span class="line">						entry = <span class="keyword">new</span> DistributedCache.DistributedCacheEntry(zip.toString(), originalEntry.f1.isExecutable, <span class="keyword">true</span>);</span><br><span class="line">					&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">						entry = <span class="keyword">new</span> DistributedCache.DistributedCacheEntry(filePath.toString(), originalEntry.f1.isExecutable, <span class="keyword">false</span>);</span><br><span class="line">					&#125;</span><br><span class="line">					jobGraph.addUserArtifact(originalEntry.f0, entry);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">				<span class="keyword">throw</span> <span class="keyword">new</span> FlinkRuntimeException(<span class="string">"Could not compress distributed-cache artifacts."</span>, ioe);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<p>该过程会根据缓存的文件是本地的还是hdfs的进入到不同的处理逻辑：</p>
<ul>
<li>本地文件或者文件夹：打成zip格式的压缩包文件，然后生成对应的分布式缓存文件</li>
<li>hdfs文件：直接创建分布式缓存文件，并将其保存到jobgraph的userArtifact字段中</li>
</ul>
<p>当Task任务执行的时候会首先从hdfs上读取文件，并将对应的文件缓存到内存中，具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br></pre></td><td class="code"><pre><span class="line">org.apache.flink.runtime.taskmanager.Task#doRun() &#123;</span><br><span class="line">		<span class="comment">// ----------------------------</span></span><br><span class="line">		<span class="comment">//  Initial State transition</span></span><br><span class="line">		<span class="comment">// ----------------------------</span></span><br><span class="line">		<span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">			ExecutionState current = <span class="keyword">this</span>.executionState;</span><br><span class="line">			<span class="keyword">if</span> (current == ExecutionState.CREATED) &#123;</span><br><span class="line">				<span class="keyword">if</span> (transitionState(ExecutionState.CREATED, ExecutionState.DEPLOYING)) &#123;</span><br><span class="line">					<span class="comment">// success, we can start our work</span></span><br><span class="line">					<span class="keyword">break</span>;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span> <span class="keyword">if</span> (current == ExecutionState.FAILED) &#123;</span><br><span class="line">				<span class="comment">// we were immediately failed. tell the TaskManager that we reached our final state</span></span><br><span class="line">				notifyFinalState();</span><br><span class="line">				<span class="keyword">if</span> (metrics != <span class="keyword">null</span>) &#123;</span><br><span class="line">					metrics.close();</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">return</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span> <span class="keyword">if</span> (current == ExecutionState.CANCELING) &#123;</span><br><span class="line">				<span class="keyword">if</span> (transitionState(ExecutionState.CANCELING, ExecutionState.CANCELED)) &#123;</span><br><span class="line">					<span class="comment">// we were immediately canceled. tell the TaskManager that we reached our final state</span></span><br><span class="line">					notifyFinalState();</span><br><span class="line">					<span class="keyword">if</span> (metrics != <span class="keyword">null</span>) &#123;</span><br><span class="line">						metrics.close();</span><br><span class="line">					&#125;</span><br><span class="line">					<span class="keyword">return</span>;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span> &#123;</span><br><span class="line">				<span class="keyword">if</span> (metrics != <span class="keyword">null</span>) &#123;</span><br><span class="line">					metrics.close();</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Invalid state for beginning of operation of task "</span> + <span class="keyword">this</span> + <span class="string">'.'</span>);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// all resource acquisitions and registrations from here on</span></span><br><span class="line">		<span class="comment">// need to be undone in the end</span></span><br><span class="line">		Map&lt;String, Future&lt;Path&gt;&gt; distributedCacheEntries = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">		AbstractInvokable invokable = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			<span class="comment">// ----------------------------</span></span><br><span class="line">			<span class="comment">//  Task Bootstrap - We periodically</span></span><br><span class="line">			<span class="comment">//  check for canceling as a shortcut</span></span><br><span class="line">			<span class="comment">// ----------------------------</span></span><br><span class="line"></span><br><span class="line">			<span class="comment">// activate safety net for task thread</span></span><br><span class="line">			LOG.info(<span class="string">"Creating FileSystem stream leak safety net for task &#123;&#125;"</span>, <span class="keyword">this</span>);</span><br><span class="line">			FileSystemSafetyNet.initializeSafetyNetForThread();</span><br><span class="line"></span><br><span class="line">			blobService.getPermanentBlobService().registerJob(jobId);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// first of all, get a user-code classloader</span></span><br><span class="line">			<span class="comment">// this may involve downloading the job's JAR files and/or classes</span></span><br><span class="line">			LOG.info(<span class="string">"Loading JAR files for task &#123;&#125;."</span>, <span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">			userCodeClassLoader = createUserCodeClassloader();</span><br><span class="line">			<span class="keyword">final</span> ExecutionConfig executionConfig = serializedExecutionConfig.deserializeValue(userCodeClassLoader);</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> (executionConfig.getTaskCancellationInterval() &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">				<span class="comment">// override task cancellation interval from Flink config if set in ExecutionConfig</span></span><br><span class="line">				taskCancellationInterval = executionConfig.getTaskCancellationInterval();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> (executionConfig.getTaskCancellationTimeout() &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">				<span class="comment">// override task cancellation timeout from Flink config if set in ExecutionConfig</span></span><br><span class="line">				taskCancellationTimeout = executionConfig.getTaskCancellationTimeout();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> (isCanceledOrFailed()) &#123;</span><br><span class="line">				<span class="keyword">throw</span> <span class="keyword">new</span> CancelTaskException();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// ----------------------------------------------------------------</span></span><br><span class="line">			<span class="comment">// register the task with the network stack</span></span><br><span class="line">			<span class="comment">// this operation may fail if the system does not have enough</span></span><br><span class="line">			<span class="comment">// memory to run the necessary data exchanges</span></span><br><span class="line">			<span class="comment">// the registration must also strictly be undone</span></span><br><span class="line">			<span class="comment">// ----------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">			LOG.info(<span class="string">"Registering task at network: &#123;&#125;."</span>, <span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">			setupPartitionsAndGates(consumableNotifyingPartitionWriters, inputGates);</span><br><span class="line"></span><br><span class="line">			<span class="keyword">for</span> (ResultPartitionWriter partitionWriter : consumableNotifyingPartitionWriters) &#123;</span><br><span class="line">				taskEventDispatcher.registerPartition(partitionWriter.getPartitionId());</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// next, kick off the background copying of files for the distributed cache</span></span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				<span class="keyword">for</span> (Map.Entry&lt;String, DistributedCache.DistributedCacheEntry&gt; entry :</span><br><span class="line">						DistributedCache.readFileInfoFromConfig(jobConfiguration)) &#123;</span><br><span class="line">					LOG.info(<span class="string">"Obtaining local cache file for '&#123;&#125;'."</span>, entry.getKey());</span><br><span class="line">					Future&lt;Path&gt; cp = fileCache.createTmpFile(entry.getKey(), entry.getValue(), jobId, executionId);</span><br><span class="line">					distributedCacheEntries.put(entry.getKey(), cp);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">				<span class="keyword">throw</span> <span class="keyword">new</span> Exception(</span><br><span class="line">					String.format(<span class="string">"Exception while adding files to distributed cache of task %s (%s)."</span>, taskNameWithSubtask, executionId), e);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> (isCanceledOrFailed()) &#123;</span><br><span class="line">				<span class="keyword">throw</span> <span class="keyword">new</span> CancelTaskException();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// ----------------------------------------------------------------</span></span><br><span class="line">			<span class="comment">//  call the user code initialization methods</span></span><br><span class="line">			<span class="comment">// ----------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">			TaskKvStateRegistry kvStateRegistry = kvStateService.createKvStateTaskRegistry(jobId, getJobVertexId());</span><br><span class="line"></span><br><span class="line">			Environment env = <span class="keyword">new</span> RuntimeEnvironment(</span><br><span class="line">				jobId,</span><br><span class="line">				vertexId,</span><br><span class="line">				executionId,</span><br><span class="line">				executionConfig,</span><br><span class="line">				taskInfo,</span><br><span class="line">				jobConfiguration,</span><br><span class="line">				taskConfiguration,</span><br><span class="line">				userCodeClassLoader,</span><br><span class="line">				memoryManager,</span><br><span class="line">				ioManager,</span><br><span class="line">				broadcastVariableManager,</span><br><span class="line">				taskStateManager,</span><br><span class="line">				aggregateManager,</span><br><span class="line">				accumulatorRegistry,</span><br><span class="line">				kvStateRegistry,</span><br><span class="line">				inputSplitProvider,</span><br><span class="line">				distributedCacheEntries,</span><br><span class="line">				consumableNotifyingPartitionWriters,</span><br><span class="line">				inputGates,</span><br><span class="line">				taskEventDispatcher,</span><br><span class="line">				checkpointResponder,</span><br><span class="line">				taskManagerConfig,</span><br><span class="line">				metrics,</span><br><span class="line">				<span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// Make sure the user code classloader is accessible thread-locally.</span></span><br><span class="line">			<span class="comment">// We are setting the correct context class loader before instantiating the invokable</span></span><br><span class="line">			<span class="comment">// so that it is available to the invokable during its entire lifetime.</span></span><br><span class="line">			executingThread.setContextClassLoader(userCodeClassLoader);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// now load and instantiate the task's invokable code</span></span><br><span class="line">			invokable = loadAndInstantiateInvokable(userCodeClassLoader, nameOfInvokableClass, env);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// ----------------------------------------------------------------</span></span><br><span class="line">			<span class="comment">//  actual task core work</span></span><br><span class="line">			<span class="comment">// ----------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">			<span class="comment">// we must make strictly sure that the invokable is accessible to the cancel() call</span></span><br><span class="line">			<span class="comment">// by the time we switched to running.</span></span><br><span class="line">			<span class="keyword">this</span>.invokable = invokable;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// switch to the RUNNING state, if that fails, we have been canceled/failed in the meantime</span></span><br><span class="line">			<span class="keyword">if</span> (!transitionState(ExecutionState.DEPLOYING, ExecutionState.RUNNING)) &#123;</span><br><span class="line">				<span class="keyword">throw</span> <span class="keyword">new</span> CancelTaskException();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// notify everyone that we switched to running</span></span><br><span class="line">			taskManagerActions.updateTaskExecutionState(<span class="keyword">new</span> TaskExecutionState(jobId, executionId, ExecutionState.RUNNING));</span><br><span class="line"></span><br><span class="line">			<span class="comment">// make sure the user code classloader is accessible thread-locally</span></span><br><span class="line">			executingThread.setContextClassLoader(userCodeClassLoader);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// run the invokable</span></span><br><span class="line">			invokable.invoke();</span><br><span class="line"></span><br><span class="line">			<span class="comment">// make sure, we enter the catch block if the task leaves the invoke() method due</span></span><br><span class="line">			<span class="comment">// to the fact that it has been canceled</span></span><br><span class="line">			<span class="keyword">if</span> (isCanceledOrFailed()) &#123;</span><br><span class="line">				<span class="keyword">throw</span> <span class="keyword">new</span> CancelTaskException();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// ----------------------------------------------------------------</span></span><br><span class="line">			<span class="comment">//  finalization of a successful execution</span></span><br><span class="line">			<span class="comment">// ----------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">			<span class="comment">// finish the produced partitions. if this fails, we consider the execution failed.</span></span><br><span class="line">			<span class="keyword">for</span> (ResultPartitionWriter partitionWriter : consumableNotifyingPartitionWriters) &#123;</span><br><span class="line">				<span class="keyword">if</span> (partitionWriter != <span class="keyword">null</span>) &#123;</span><br><span class="line">					partitionWriter.finish();</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// try to mark the task as finished</span></span><br><span class="line">			<span class="comment">// if that fails, the task was canceled/failed in the meantime</span></span><br><span class="line">			<span class="keyword">if</span> (!transitionState(ExecutionState.RUNNING, ExecutionState.FINISHED)) &#123;</span><br><span class="line">				<span class="keyword">throw</span> <span class="keyword">new</span> CancelTaskException();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// unwrap wrapped exceptions to make stack traces more compact</span></span><br><span class="line">			<span class="keyword">if</span> (t <span class="keyword">instanceof</span> WrappingRuntimeException) &#123;</span><br><span class="line">				t = ((WrappingRuntimeException) t).unwrap();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// ----------------------------------------------------------------</span></span><br><span class="line">			<span class="comment">// the execution failed. either the invokable code properly failed, or</span></span><br><span class="line">			<span class="comment">// an exception was thrown as a side effect of cancelling</span></span><br><span class="line">			<span class="comment">// ----------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				<span class="comment">// check if the exception is unrecoverable</span></span><br><span class="line">				<span class="keyword">if</span> (ExceptionUtils.isJvmFatalError(t) ||</span><br><span class="line">						(t <span class="keyword">instanceof</span> OutOfMemoryError &amp;&amp; taskManagerConfig.shouldExitJvmOnOutOfMemoryError())) &#123;</span><br><span class="line"></span><br><span class="line">					<span class="comment">// terminate the JVM immediately</span></span><br><span class="line">					<span class="comment">// don't attempt a clean shutdown, because we cannot expect the clean shutdown to complete</span></span><br><span class="line">					<span class="keyword">try</span> &#123;</span><br><span class="line">						LOG.error(<span class="string">"Encountered fatal error &#123;&#125; - terminating the JVM"</span>, t.getClass().getName(), t);</span><br><span class="line">					&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">						Runtime.getRuntime().halt(-<span class="number">1</span>);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				<span class="comment">// transition into our final state. we should be either in DEPLOYING, RUNNING, CANCELING, or FAILED</span></span><br><span class="line">				<span class="comment">// loop for multiple retries during concurrent state changes via calls to cancel() or</span></span><br><span class="line">				<span class="comment">// to failExternally()</span></span><br><span class="line">				<span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">					ExecutionState current = <span class="keyword">this</span>.executionState;</span><br><span class="line"></span><br><span class="line">					<span class="keyword">if</span> (current == ExecutionState.RUNNING || current == ExecutionState.DEPLOYING) &#123;</span><br><span class="line">						<span class="keyword">if</span> (t <span class="keyword">instanceof</span> CancelTaskException) &#123;</span><br><span class="line">							<span class="keyword">if</span> (transitionState(current, ExecutionState.CANCELED)) &#123;</span><br><span class="line">								cancelInvokable(invokable);</span><br><span class="line">								<span class="keyword">break</span>;</span><br><span class="line">							&#125;</span><br><span class="line">						&#125;</span><br><span class="line">						<span class="keyword">else</span> &#123;</span><br><span class="line">							<span class="keyword">if</span> (transitionState(current, ExecutionState.FAILED, t)) &#123;</span><br><span class="line">								<span class="comment">// proper failure of the task. record the exception as the root cause</span></span><br><span class="line">								failureCause = t;</span><br><span class="line">								cancelInvokable(invokable);</span><br><span class="line"></span><br><span class="line">								<span class="keyword">break</span>;</span><br><span class="line">							&#125;</span><br><span class="line">						&#125;</span><br><span class="line">					&#125;</span><br><span class="line">					<span class="keyword">else</span> <span class="keyword">if</span> (current == ExecutionState.CANCELING) &#123;</span><br><span class="line">						<span class="keyword">if</span> (transitionState(current, ExecutionState.CANCELED)) &#123;</span><br><span class="line">							<span class="keyword">break</span>;</span><br><span class="line">						&#125;</span><br><span class="line">					&#125;</span><br><span class="line">					<span class="keyword">else</span> <span class="keyword">if</span> (current == ExecutionState.FAILED) &#123;</span><br><span class="line">						<span class="comment">// in state failed already, no transition necessary any more</span></span><br><span class="line">						<span class="keyword">break</span>;</span><br><span class="line">					&#125;</span><br><span class="line">					<span class="comment">// unexpected state, go to failed</span></span><br><span class="line">					<span class="keyword">else</span> <span class="keyword">if</span> (transitionState(current, ExecutionState.FAILED, t)) &#123;</span><br><span class="line">						LOG.error(<span class="string">"Unexpected state in task &#123;&#125; (&#123;&#125;) during an exception: &#123;&#125;."</span>, taskNameWithSubtask, executionId, current);</span><br><span class="line">						<span class="keyword">break</span>;</span><br><span class="line">					&#125;</span><br><span class="line">					<span class="comment">// else fall through the loop and</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">catch</span> (Throwable tt) &#123;</span><br><span class="line">				String message = String.format(<span class="string">"FATAL - exception in exception handler of task %s (%s)."</span>, taskNameWithSubtask, executionId);</span><br><span class="line">				LOG.error(message, tt);</span><br><span class="line">				notifyFatalError(message, tt);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">finally</span> &#123;</span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				LOG.info(<span class="string">"Freeing task resources for &#123;&#125; (&#123;&#125;)."</span>, taskNameWithSubtask, executionId);</span><br><span class="line"></span><br><span class="line">				<span class="comment">// clear the reference to the invokable. this helps guard against holding references</span></span><br><span class="line">				<span class="comment">// to the invokable and its structures in cases where this Task object is still referenced</span></span><br><span class="line">				<span class="keyword">this</span>.invokable = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">				<span class="comment">// free the network resources</span></span><br><span class="line">				releaseNetworkResources();</span><br><span class="line"></span><br><span class="line">				<span class="comment">// free memory resources</span></span><br><span class="line">				<span class="keyword">if</span> (invokable != <span class="keyword">null</span>) &#123;</span><br><span class="line">					memoryManager.releaseAll(invokable);</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				<span class="comment">// remove all of the tasks library resources</span></span><br><span class="line">				libraryCache.unregisterTask(jobId, executionId);</span><br><span class="line">				fileCache.releaseJob(jobId, executionId);</span><br><span class="line">				blobService.getPermanentBlobService().releaseJob(jobId);</span><br><span class="line"></span><br><span class="line">				<span class="comment">// close and de-activate safety net for task thread</span></span><br><span class="line">				LOG.info(<span class="string">"Ensuring all FileSystem streams are closed for task &#123;&#125;"</span>, <span class="keyword">this</span>);</span><br><span class="line">				FileSystemSafetyNet.closeSafetyNetAndGuardedResourcesForThread();</span><br><span class="line"></span><br><span class="line">				notifyFinalState();</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">				<span class="comment">// an error in the resource cleanup is fatal</span></span><br><span class="line">				String message = String.format(<span class="string">"FATAL - exception in resource cleanup of task %s (%s)."</span>, taskNameWithSubtask, executionId);</span><br><span class="line">				LOG.error(message, t);</span><br><span class="line">				notifyFatalError(message, t);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// un-register the metrics at the end so that the task may already be</span></span><br><span class="line">			<span class="comment">// counted as finished when this happens</span></span><br><span class="line">			<span class="comment">// errors here will only be logged</span></span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				metrics.close();</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">				LOG.error(<span class="string">"Error during metrics de-registration of task &#123;&#125; (&#123;&#125;)."</span>, taskNameWithSubtask, executionId, t);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<p>关于分布式缓存的参见注释：// next, kick off the background copying of files for the distributed cache，这一段代码就是将缓存到hdfs的文件copy到内存中，不过这里是copy到taskmanager的内存中，因此集群中存在多少个taskmanager就会和hdfs交互多少次，从中读取文件到内存中，不过在读取到内存中task的并行多是多少就会有多少次和taskmanager内存交互来读取数据，关于这一点我们可以做个简单的验证，那就是将mapper的并行度设置为1:
<img src="//southrivers.github.io/2022/08/20/flink-解析/once.png" alt>
上面当我们手动将mapper的并行度调整为1的时候可以看到，这种情况下open方法只会被执行一次。</p>
<!-- https://developpaper.com/principle-and-application-of-flink-distributed-cache/ -->

<p>TODO 对于启用了checkpoint的分布式缓存的恢复有待研究，应该不会有所不同</p>
<h3 id="重启策略"><a href="#重启策略" class="headerlink" title="重启策略"></a>重启策略</h3><p>flink作业的执行是在分布式的环境上进行执行的，不考虑operator chian的情况下某一个operator对应的task在执行的过程中可能会运行失败，因此我们需要针对这种故障恢复需要定制重启策略，关于故障恢复的策略有full和region两种形式，full类型的故障恢复会导致整个作业重启，这样可能会导致集群消息积压，region类型的故障恢复首先会将作业按照一定的策略划分为region，然后会将上下游受影响的region进行重启，如下图所示:
<img src="//southrivers.github.io/2022/08/20/flink-解析/failover.png" alt>
我们可以将region理解为两个不存在关联的图。</p>
<p>以上两种故障转移都涉及到任务的重启，在作业没有开启checkpoint的情况下即便配置了故障转移，作业也不会重启，只有配置了checkpoint的情况下才会在失败的时候重启，重启的策略有以下几种：</p>
<ul>
<li>norestart：这种是不重启策略</li>
<li>fixed delay：这种是制定每隔多长时间启动一次，并且设定了最大的启动次数</li>
<li>失败率重启：这种方式是也是指定每隔多长时间启动一次，不过在启动的时间内，会对失败的次数进行统计<!-- https://cpeixin.cn/2020/08/08/Flink-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%E5%92%8C%E9%87%8D%E5%90%AF%E7%AD%96%E7%95%A5/ -->
<!-- https://cwiki.apache.org/confluence/display/FLINK/FLIP-1+%3A+Fine+Grained+Recovery+from+Task+Failures -->
下面使用一段代码演示一下重启策略的应用，不过开启代码之前首先需要开启故障转移，该策略需要通过 Flink 配置文件 flink-conf.yaml 中的 jobmanager.execution.failover-strategy 配置项进行配置，其对应的值有两种full和region，演示代码如下：</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 启用checkpoint机制</span></span><br><span class="line">CheckpointConfig config = env.getCheckpointConfig();</span><br><span class="line">config.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line"><span class="comment">// 配置重启策略</span></span><br><span class="line">env.setRestartStrategy(<span class="keyword">new</span> RestartStrategies.NoRestartStrategyConfiguration());</span><br></pre></td></tr></table></figure>

<p>checkpoint是重启策略的充分非必要条件，也就是开启重启要求开启checkpoint，但是开启checkpoint可以不开启重启策略，如果单纯的开启了checkpoint的策略，我们只需要在手动重启作业的时候指定使用的那个checkpoint，作业在运行的时候就会在该checkpoint重启，<strong>不过如果用户制定了重启的策略，那么作业就是从最近的checkpoint进行重启了， TODO 待验证 <code>bin/flink run -s :checkpointMetaDataPath [:runArgs]</code></strong></p>
<h3 id="并行度"><a href="#并行度" class="headerlink" title="并行度"></a>并行度</h3><p>并行度是一个算子可以拆分成多少个子任务的标记，并行度越大作业将会执行的越快，常见的设置作业并行度的方式有以下几种：</p>
<ul>
<li>算子级别设置</li>
<li>env环境变量设置</li>
<li>flink提交命令行设置</li>
<li>flink-conf.yaml配置文件中配置</li>
</ul>
<p>以上几种方式优先级逐次下降，通常推荐使用算子级别的配置</p>
<h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><h3 id="检查点"><a href="#检查点" class="headerlink" title="检查点"></a>检查点</h3><p>检查点默认是将集群的状态保存起来，对于状态的存储当前有三种模式：</p>
<ul>
<li>memorystatebackend</li>
<li>fsstatebackend</li>
<li>rocksdbstatebackend
checkpoint的启用依赖于集群模式，对于本地模式是没有办法开启的，这里后续再详细分析，</li>
</ul>
<h3 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h3><p>状态是数据处理过程中一些中间的数据，状态的分类有keyedstate、operaterstate，keyedstate是应用在keyedstream上的state，不同的key将会访问不同的state，operatestate则是针对所有的key都可以访问的状态，operatestate可以认为是keyedstate一种特殊情况，即所有的key都可以访问的状态，state和一般变量最大的不同点在于flink作业在做checkpoint的时候（当然是开启了checkpoint的情况下）是否会将对应的变量持久化，可以持久化的就是state，否则一旦任务失败重启，状态就没有办法恢复了。</p>
<p>需要注意的是状态是存在于taskmanager的堆内存中的，而且是针对了不同的subtask，也就是说如果一个operater被实例化成了一个task（依照并行度会划分成多个subtask），不同的subtask之间状态是不共享的（这种可以通过代码证明）：</p>
<p>不同的subtask访问的状态不是同一个</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.myorg.quickstart;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.ReduceFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.RichFlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.RichMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ListState;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ListStateDescriptor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueState;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueStateDescriptor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.typeinfo.TypeHint;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.typeinfo.TypeInformation;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StateTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 初始化环境变量</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="comment">// 添加数据源</span></span><br><span class="line">        DataStream&lt;String&gt; words = env.socketTextStream(<span class="string">"localhost"</span>, <span class="number">11000</span>);</span><br><span class="line">        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; wordsMap = words.flatMap(<span class="keyword">new</span> RichFlatMapFunction&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="comment">// 定义变量</span></span><br><span class="line"><span class="comment">//            ListState&lt;Tuple2&lt;String, Integer&gt;&gt; valueState = null;</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">                <span class="comment">//定义句柄，句柄和要指向的变量类型要保持一致，这一步的目的是为了让chekpoint的时候状态可以保存下来</span></span><br><span class="line">                ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; valueStateDescriptor =</span><br><span class="line">                        <span class="keyword">new</span> ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt;(<span class="string">"vsd"</span>, TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;String, Integer&gt;&gt;()&#123;&#125;));</span><br><span class="line">                <span class="comment">// 这一步是将后面这个句柄绑定到前面这个变量，句柄可以看作是真正内存空间的句柄</span></span><br><span class="line"><span class="comment">//                valueState = getRuntimeContext().getListState(valueStateDescriptor);</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// FIXME 只可以在source和sink中使用operate state？？？？？？？？ 貌似是的</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                String[] values = value.split(<span class="string">"\\s"</span>);</span><br><span class="line">                <span class="keyword">for</span> (String v : values) &#123;</span><br><span class="line">                    <span class="comment">// 统计该时间周期内hello出现的次数</span></span><br><span class="line">                    <span class="keyword">if</span> (v.equals(<span class="string">"hello"</span>)) &#123;</span><br><span class="line">                        <span class="comment">// FIXME 因为是operater state，所以其状态只可以add，不可以update</span></span><br><span class="line"><span class="comment">//                        valueState.add(Tuple2.of(v, 1));</span></span><br><span class="line">                    &#125;</span><br><span class="line">                    out.collect(Tuple2.of(v, <span class="number">1</span>));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// TODO 这一步应该是执行任务的并行度的次数，可以顺带观察引用是否一致，进而判断内存的valuestate是否是隔离的，因为当前是非keyedstate</span></span><br><span class="line"><span class="comment">//                System.out.println(valueState);</span></span><br><span class="line">                <span class="comment">// 重置该时间窗口内的状态信息，TODO 这个应该是一个subtask在一个窗口期内只会执行一次的动作</span></span><br><span class="line"><span class="comment">//                valueState.clear();</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).keyBy(<span class="number">0</span>).map(<span class="keyword">new</span> RichMapFunction&lt;Tuple2&lt;String, Integer&gt;, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// TODO state包含了多种类型，liststate等信息，可以仔细研究一下</span></span><br><span class="line">            ValueState&lt;Tuple2&lt;String, Integer&gt;&gt; wordState = <span class="keyword">null</span>;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                ValueStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; wordStateDescriptor =</span><br><span class="line">                        <span class="keyword">new</span> ValueStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt;(<span class="string">"words"</span>, TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">                        &#125;));</span><br><span class="line">                wordState = getRuntimeContext().getState(wordStateDescriptor);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">map</span><span class="params">(Tuple2&lt;String, Integer&gt; value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">null</span> == wordState.value()) &#123;</span><br><span class="line">                    wordState.update(Tuple2.of(<span class="string">"null"</span>, <span class="number">0</span>));</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(<span class="string">"value state"</span>);</span><br><span class="line">                wordState.update(Tuple2.of(<span class="string">"null"</span>, wordState.value().f1 + value.f1));</span><br><span class="line">                <span class="comment">// TODO 判断对应的state是否是同一个，当前是keyedstate，接下来可以更改并行度</span></span><br><span class="line">                System.out.println(wordState);</span><br><span class="line">                <span class="keyword">return</span> value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).keyBy(<span class="number">0</span>).timeWindow(Time.seconds(<span class="number">5</span>), Time.seconds(<span class="number">5</span>)).reduce(<span class="keyword">new</span> ReduceFunction&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">reduce</span><span class="params">(Tuple2&lt;String, Integer&gt; value1, Tuple2&lt;String, Integer&gt; value2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                value1.f1 = value1.f1 + value2.f1;</span><br><span class="line">                <span class="keyword">return</span> value1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        wordsMap.print();</span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对上述代码输入测试数据：
<img src="//southrivers.github.io/2022/08/20/flink-解析/stateecho.png" alt>
上述输入对应的结果如下：
<img src="//southrivers.github.io/2022/08/20/flink-解析/stateres.png" alt>
通过上述代码可以看到我们的keyedstate的state也是针对subtask级别的对象，因此在并行度设置为8的情况下，可以看到最终是会生成8个对象，不同的key被分配到不同的subtask中，并且会更新对应的状态，<strong>这里也可以很明显的看出来state的个数并不是key的个数，而仅仅是任务的并行数，说明了不同的key存放在了同一个state中</strong>，上述情况中尚未讨论的一种情况是operatestate，对于该种类型的状态应该是针对source或者sink才会使用的（使用场景及用法待明确）</p>
<p>不过上面的代码并没有开启checkpoint，因此对于keyedstate的测试代码来说，其效果等价于定一一个map，也就是说在任务终结的时候状态就会丢失了</p>
<p>接下来我们用一段代码来演示flink operate state状态的使用</p>
<p>另外针对故障重启的代码测试，需要搭建集群环境来进行调测</p>
<!-- https://www.cnblogs.com/saowei/p/16039673.html -->

<p>除了上述按照是否是keyedstream来划分状态外，还可以按照状态托管的方式将其划分为manage state和raw state，从名字也可以看出来，对于manage state其状态的托管交给了flink框架，而raw state的托管则需要程序员自己来实现，另外在真实的使用flink的state的时候，如果并行度发生了改变，也会导致生产环境中出现问题，待分析</p>
<h3 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h3><h3 id="exactly-once"><a href="#exactly-once" class="headerlink" title="exactly-once"></a>exactly-once</h3><p>exactly-once的实现应该是不依赖于checkpoint，不过checkpoint的实现中有atleast-once的语意和exact-once的语意，这个和二阶段提交的exactly-once应该是有所不同的</p>
<h2 id="反压"><a href="#反压" class="headerlink" title="反压"></a>反压</h2><p>窗口、时间</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1>
            
                

            
        </div>
        <div class="post-tool">
            <a class="btn-thumbs-up" href="javascript:void(0);" data-cid="52" title="95">
                <i class="fa fa-thumbs-up" aria-hidden="true"></i> 打赏
            </a>
        </div>
        
        <div class="post-tags">tags：
            
        </div>
        
    </article>
    
        <p style="text-align: center">本文代表个人观点，内容仅供参考</p>
    
    
    

</div>
<script src="/js/busuanzi.pure.mini.js"></script>


        </div><!-- end #main-->
    </div><!-- end #body -->
    <footer class="footer">
    <div class="footer-inner" style="text-align: center">

    </div>
</footer>
<script src="/js/SimpleCore.js"></script>

</div>
<!-- search pop -->
<div class="popup search-popup local-search-popup">
    <div class="local-search-header clearfix">
        <span class="search-icon">
            <i class="fa fa-search"></i>
        </span>
        <span class="popup-btn-close">
            <i class="fa fa-times-circle"></i>
        </span>
        <div class="local-search-input-wrapper">
            <input id="local-search-input" spellcheck="false" type="text" autocomplete="off" placeholder="请输入查询关键词">
        </div>
    </div>
    <div id="local-search-result"></div>
</div>
<div class="fixed-btn">
    <a class="btn-gotop" href="javascript:"> <i class="fa fa-angle-up"></i></a>
</div>
<script>
    $(function () {
        var jsi_config = {
            buildingTime: '01/20/2018',
            current: $('.post-tags').length > 0 ? 'post' : 'archive',
            snsQRCode: '/images/sns-qrcode.png',
            donateImg: '/images/donate-qr.png',
            localSearch: { dbPath: '' },
            readMode: 'day'
        };
        
            jsi_config.localSearch = {
                dbPath: '/search.xml',
                trigger: 'auto',
                topN: '1',
                unescape: 'false'
            }
        
        SimpleCore.init(jsi_config);
        
    });
</script>
</body>
</html>
